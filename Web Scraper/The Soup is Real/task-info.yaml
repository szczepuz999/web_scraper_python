type: edu
files:
- name: scraper.py
  visible: true
  text: |-
    import requests
    from bs4 import BeautifulSoup
    import json


    def get_ld_json(url: str) -> dict:
        parser = "html.parser"
        req = requests.get(url, headers={'Accept-Language': 'en-US,en;q=0.5'})
        soup = BeautifulSoup(req.text, parser)
        return json.loads("".join(soup.find("script", {"type": "application/ld+json"}).contents))

    def scraper_title(url):
        parser = "html.parser"
        req = requests.get(url, headers={'Accept-Language': 'en-US,en;q=0.5'})
        soup = BeautifulSoup(req.text, parser)
        title = soup.findAll('title')
        # for i in title:
        #     print(i.text)
        return title[0].text
    def apostrophe_fix(text):
        if "&apos" in text:
            new_text = text.replace("&apos;", "'")
        else: new_text = text
        return new_text


    # scraper('http://api.quotable.io/quotes/asdf')
    url = input("Input the URL:\n")
    correct_url = "www.imdb.com"
    if correct_url in url:
        a = (get_ld_json(url))
        # print(a["@type"])
        if a["@type"] == "Movie" or a["@type"] == "TVSeries":
            # x = dict(title=a["name"], description=a["description"])
            x={}
            x["title"] = scraper_title(url)
            x["description"] = apostrophe_fix(a["description"])
            print("")
            print(x)
        else:
            print("\nInvalid movie page!")
    else: print("\nInvalid movie page!")

    # scraper_title(url)

    # a = (get_ld_json(url))
    # print(a['trailer']['description'])
    # print(apostrophe_fix("An organized crime dynasty&apos;s aging patriarch t"))
  learner_created: false
- name: tests.py
  visible: false
  text: |
    import glob
    import os
    import random
    import re
    import string

    import requests
    from bs4 import BeautifulSoup
    from furl import furl
    from hstest.check_result import CheckResult
    from hstest.stage_test import StageTest
    from hstest.test_case import TestCase


    class NatureScraper:
        def tag_leading_to_view_article(self, tag):
            return tag.has_attr("data-track-action") and tag["data-track-action"] == "view article"

        def tag_containing_atricle_type(self, tag):
            return tag.name == "span" and tag.has_attr("data-test") and tag["data-test"] == "article.type"

        def tag_containing_article_title(self, tag):
            return tag.name == "h1" and ("article" in tag["class"][0] and "title" in tag["class"][0])

        def tag_containing_article_body(self, tag):
            return tag.name == "div" and ("article" in tag.get("class", [""])[0] and "body" in tag.get("class", [""])[0])

        def get_article_links_of_type(self, url, article_type="News"):
            origin_url = furl(url).origin
            try:
                articles_resp = requests.get(url)
            except Exception:
                return CheckResult.wrong("An error occurred when tests tried to connect to the Internet page.\n"
                                         "Please, try again.")
            soup = BeautifulSoup(articles_resp.text, "html.parser")
            articles = soup.find_all(self.tag_containing_atricle_type)
            articles = list(filter(lambda x: x.text.strip() == article_type, articles))
            return [
                furl(origin_url).add(path=x.find_parent("article").find(self.tag_leading_to_view_article).get("href")).url \
                for x in articles]

        def get_article_title_and_content(self, url):
            try:
                article = requests.get(url)
            except Exception:
                return CheckResult.wrong("An error occurred when tests tried to connect to the Internet page.\n"
                                         "Please, try again.")
            soup = BeautifulSoup(article.text, "html.parser")
            title = soup.find(self.tag_containing_article_title)
            content = soup.find(self.tag_containing_article_body)
            if title and content:
                return title.text.strip(), content.text.strip()
            else:
                return title, content


    class WebScraperTest(StageTest):
        def generate(self):
            txt_files = glob.glob("*.txt")
            for filename in txt_files:
                try:
                    os.remove(filename)
                except FileNotFoundError:
                    pass
            return [TestCase(time_limit=0)]

        def check(self, reply, attach=None):
            scraper = NatureScraper()
            txt_files = glob.glob("*.txt")
            article_links = scraper.get_article_links_of_type("https://www.nature.com/nature/articles")
            if len(txt_files) != len(article_links):
                return CheckResult.wrong("A wrong number of files with articles was found. \n"
                                         "{0} files were found, {1} files were expected.".format(len(txt_files),
                                                                                                 len(article_links)))

            if not article_links:
                return CheckResult.correct()
            title, content = None, None
            while not title or not content:
                article_n = random.randint(0, len(article_links) - 1)
                title, content = scraper.get_article_title_and_content(article_links[article_n])
                if not title or not content:
                    article_links.pop(article_n)
                    if not article_links:
                        return CheckResult.correct()
            title = f"{title.translate(str.maketrans('', '', string.punctuation)).replace(' ', '_')}.txt"
            if not os.path.exists(title):
                return CheckResult.wrong("A file with the name \"{0}\" was not found.\n"
                                         "Make sure you remove punctuation and \nreplace the whitespaces with underscores in the titles.".format(
                    title))
            with open(title, "rb") as f:
                try:
                    file_content = f.read().decode('utf-8').strip()
                except UnicodeDecodeError:
                    return CheckResult.wrong("An error occurred when tests tried to read the file \"{0}\"\n"
                                             "Please, make sure you save your file in binary format \n"
                                             "and encode the saved data using utf-8 encoding.".format(title))
            file_content = re.sub('[\r\n]', '', file_content)
            content = re.sub('[\r\n]', '', content)
            if content in file_content:
                return CheckResult.correct()
            else:
                return CheckResult.wrong("Some of the files do not contain the expected article's body. \n"
                                         "The tests expected the following article:\n"
                                         f"\"{content}\"\n"
                                         f"However, the following text was found in the file {title}:\n"
                                         f"\"{file_content}\"")


    if __name__ == '__main__':
        WebScraperTest().run_tests()
  learner_created: false
- name: source.html
  visible: true
  text: |
    <html>
    <head>
      <title>warming up</title>
      <link rel="stylesheet" type="text/css" href="../style.css">
    </head>
    <body>
    <center>
    <img src="calc.jpg"><br>
    <font color="gold">
    <p>Hint: try to change the URL address.
    </body>
    </html>
  learner_created: true
- name: '%CureVac_COVID_vaccine_letdown_spotlights_mRNA_design_challenges%.html'
  visible: true
  learner_created: true
- name: '%How_scientists_are_embracing_NFTs%.html'
  visible: true
  learner_created: true
- name: '%Mathematicians_welcome_computerassisted_proof_in_grand_unification_theory%.html'
  visible: true
  learner_created: true
- name: How_scientists_are_embracing_NFTs.txt
  visible: true
  learner_created: true
- name: Mathematicians_welcome_computerassisted_proof_in_grand_unification_theory.txt
  visible: true
  learner_created: true
- name: CureVac_COVID_vaccine_letdown_spotlights_mRNA_design_challenges.txt
  visible: true
  learner_created: true
feedback_link: https://hyperskill.org/projects/145/stages/784/implement#comment
status: Solved
feedback:
  message: Congratulations!
  time: Sun, 20 Jun 2021 05:21:57 UTC
record: -1
